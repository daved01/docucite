{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "import os\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constants and setup\n",
    "openai.api_key = os.environ[\"OPENAI_API_KEY\"]\n",
    "\n",
    "PDF_PATH = \"./data/Fluent Python.pdf\"\n",
    "PDF_PATH = \"./data/Python summary.pdf\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Document loader\n",
    "- Load the book.\n",
    "\n",
    "- Add chapter title to metadata."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders import PyPDFLoader\n",
    "\n",
    "loader = PyPDFLoader(PDF_PATH)\n",
    "pages = loader.load_and_split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "65"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(pages)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "CHUNK_SIZE = 200\n",
    "CHUNK_OVERLAP = 50\n",
    "\n",
    "\n",
    "splitter = RecursiveCharacterTextSplitter(chunk_size=CHUNK_SIZE, chunk_overlap=CHUNK_OVERLAP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = splitter.split_documents(pages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Document(page_content='81.2.4 Tuples Are Not Just Immutable Lists\\t\\n81.2.5 Unpacking Sequences and Iterables\\t\\n81.2.6 Pattern Matching with Sequences\\t\\n91.2.7 Slicing\\t\\n91.2.8 Lists, arrays, deques', metadata={'source': './data/Python summary.pdf', 'page': 0})"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Storage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "expected string or buffer",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[29], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mlangchain\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39membeddings\u001b[39;00m \u001b[39mimport\u001b[39;00m OpenAIEmbeddings\n\u001b[1;32m      3\u001b[0m embedding \u001b[39m=\u001b[39m OpenAIEmbeddings()\n\u001b[0;32m----> 4\u001b[0m doc_result \u001b[39m=\u001b[39m embedding\u001b[39m.\u001b[39;49membed_documents(docs)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.11.3/envs/3.11.3-langchain/lib/python3.11/site-packages/langchain/embeddings/openai.py:508\u001b[0m, in \u001b[0;36mOpenAIEmbeddings.embed_documents\u001b[0;34m(self, texts, chunk_size)\u001b[0m\n\u001b[1;32m    496\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Call out to OpenAI's embedding endpoint for embedding search docs.\u001b[39;00m\n\u001b[1;32m    497\u001b[0m \n\u001b[1;32m    498\u001b[0m \u001b[39mArgs:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    504\u001b[0m \u001b[39m    List of embeddings, one for each text.\u001b[39;00m\n\u001b[1;32m    505\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    506\u001b[0m \u001b[39m# NOTE: to keep things simple, we assume the list may contain texts longer\u001b[39;00m\n\u001b[1;32m    507\u001b[0m \u001b[39m#       than the maximum context and use length-safe embedding function.\u001b[39;00m\n\u001b[0;32m--> 508\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_get_len_safe_embeddings(texts, engine\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdeployment)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.11.3/envs/3.11.3-langchain/lib/python3.11/site-packages/langchain/embeddings/openai.py:335\u001b[0m, in \u001b[0;36mOpenAIEmbeddings._get_len_safe_embeddings\u001b[0;34m(self, texts, engine, chunk_size)\u001b[0m\n\u001b[1;32m    331\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel\u001b[39m.\u001b[39mendswith(\u001b[39m\"\u001b[39m\u001b[39m001\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[1;32m    332\u001b[0m     \u001b[39m# See: https://github.com/openai/openai-python/issues/418#issuecomment-1525939500\u001b[39;00m\n\u001b[1;32m    333\u001b[0m     \u001b[39m# replace newlines, which can negatively affect performance.\u001b[39;00m\n\u001b[1;32m    334\u001b[0m     text \u001b[39m=\u001b[39m text\u001b[39m.\u001b[39mreplace(\u001b[39m\"\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39m \u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m--> 335\u001b[0m token \u001b[39m=\u001b[39m encoding\u001b[39m.\u001b[39;49mencode(\n\u001b[1;32m    336\u001b[0m     text,\n\u001b[1;32m    337\u001b[0m     allowed_special\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mallowed_special,\n\u001b[1;32m    338\u001b[0m     disallowed_special\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdisallowed_special,\n\u001b[1;32m    339\u001b[0m )\n\u001b[1;32m    340\u001b[0m \u001b[39mfor\u001b[39;00m j \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39m0\u001b[39m, \u001b[39mlen\u001b[39m(token), \u001b[39mself\u001b[39m\u001b[39m.\u001b[39membedding_ctx_length):\n\u001b[1;32m    341\u001b[0m     tokens \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m [token[j : j \u001b[39m+\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39membedding_ctx_length]]\n",
      "File \u001b[0;32m~/.pyenv/versions/3.11.3/envs/3.11.3-langchain/lib/python3.11/site-packages/tiktoken/core.py:116\u001b[0m, in \u001b[0;36mEncoding.encode\u001b[0;34m(self, text, allowed_special, disallowed_special)\u001b[0m\n\u001b[1;32m    114\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(disallowed_special, \u001b[39mfrozenset\u001b[39m):\n\u001b[1;32m    115\u001b[0m         disallowed_special \u001b[39m=\u001b[39m \u001b[39mfrozenset\u001b[39m(disallowed_special)\n\u001b[0;32m--> 116\u001b[0m     \u001b[39mif\u001b[39;00m match \u001b[39m:=\u001b[39m _special_token_regex(disallowed_special)\u001b[39m.\u001b[39;49msearch(text):\n\u001b[1;32m    117\u001b[0m         raise_disallowed_special_token(match\u001b[39m.\u001b[39mgroup())\n\u001b[1;32m    119\u001b[0m \u001b[39mtry\u001b[39;00m:\n",
      "\u001b[0;31mTypeError\u001b[0m: expected string or buffer"
     ]
    }
   ],
   "source": [
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "from langchain.vectorstores import Chroma\n",
    "\n",
    "embedding = OpenAIEmbeddings()\n",
    "persist_directory = 'data/chroma'\n",
    "\n",
    "vectordb = Chroma.from_documents(documents=docs, \n",
    "                                 embedding=embedding, \n",
    "                                 persist_directory=persist_directory\n",
    "                                 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Retrieval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "3.11.3-langchain",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
